#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä» attack.log ä¸ conversation_history.txt ä¸­æŠ½å–å¹¶åŒ¹é…æ•°æ®ï¼Œç”Ÿæˆæ¯æ¬¡æ”»å‡»ä¸€è¡Œçš„å®éªŒç»“æœæ–‡ä»¶ extracted_attacks.csv
extracted_attacks.csvã€‚CSV åŒ…å«çš„åˆ—ï¼ˆå¯æŒ‰éœ€æ‰©å±•ï¼‰ï¼š
	attack_idï¼šæ”»å‡»ç¼–å·ï¼ˆä»1å¼€å§‹ï¼‰
	attackerï¼šæ”»å‡»è€…ï¼ˆä¾‹å¦‚ ['uav3']ï¼‰
	targetï¼šç›®æ ‡ï¼ˆä¾‹å¦‚ uav2 æˆ– IPï¼‰
	attack_startï¼šæ”»å‡»å¼€å§‹æ—¶é—´ï¼ˆepoch ç§’ï¼‰
	attack_endï¼šæ”»å‡»ç»“æŸæ—¶é—´ï¼ˆepoch ç§’ï¼ŒæŒ‰æ—¥å¿—ä¸­çš„æ—¶é•¿æˆ–é»˜è®¤æ—¶é•¿è®¡ç®—ï¼‰
	detection_timeï¼šæ£€æµ‹æ—¶é—´ï¼ˆå¦‚æœæœ‰ï¼Œepoch ç§’ï¼‰
	attack_detectedï¼šå¸ƒå°”ï¼ˆTrue/Falseï¼‰
	attack_typeï¼šå­—ç¬¦ä¸²ï¼ˆå¦‚ ddosï¼‰
	security_score_csï¼šæµ®ç‚¹ï¼ˆå®‰å…¨åˆ†æ•°ï¼‰
	defense_timeï¼šæ£€æµ‹æ—¶é—´ï¼ˆå¦‚æœæœ‰ï¼Œepoch ç§’ï¼‰
	defense_commandsï¼šJSON å­—ç¬¦ä¸²ï¼ˆé˜²å¾¡å‘½ä»¤æ•°ç»„ï¼‰
	px4_commandï¼šï¼ˆè‹¥å­˜åœ¨ï¼‰px4_command æ–‡æœ¬

ç”¨æ³•:
    python extract_attack_results.py \
        --attack_log attack.log \
        --conv_log conversation_history.txt \
        --out extracted_attacks.csv \
        --default_duration 60 \
        --timezone UTC

æ³¨æ„:
- è„šæœ¬å°½é‡å…¼å®¹å¤šç§æ—¶é—´æ ¼å¼ï¼›å¦‚æœ conversation_history çš„ Time è¡Œä½¿ç”¨æœ¬åœ°æ—¶åŒºï¼Œè¯·ä¼ å…¥ --timezone å‚æ•°ï¼ˆä¾‹å¦‚ "+08:00" æˆ– "Asia/Shanghai"ï¼‰
- éœ€è¦ pandas åº“: pip install pandas
"""

import re
import json
import argparse
from datetime import datetime, timezone, timedelta
import time
import pandas as pd

# -----------------------
# é…ç½®é»˜è®¤å€¼
# -----------------------
DEFAULT_ATTACK_DURATION = 60.0  # é»˜è®¤æ”»å‡»æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œè‹¥ attack.log æœªæä¾›åˆ™ä½¿ç”¨
# -----------------------

def parse_attack_log(path, default_duration=DEFAULT_ATTACK_DURATION):
    """
    è§£æ attack.logï¼Œè¿”å›æ”»å‡»äº‹ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªäº‹ä»¶ä¸º dict:
    {
      'attack_id': int,
      'attacker': str or list,
      'target': str,
      'attack_start_epoch': float,
      'duration': float
    }
    è„šæœ¬ä¼šå°è¯•è§£æè¡Œä¸­ç»™å‡ºçš„æ—¶é•¿ï¼ˆå¦‚ 'æ—¶é•¿=10s'ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ default_durationã€‚
    æ”¯æŒå¤šç§è¡Œæ ¼å¼ï¼ˆåŸºæœ¬ç”¨æ­£åˆ™æå–ï¼‰ã€‚
    """
    attacks = []
    id_counter = 1
    with open(path, 'r', encoding='utf-8') as f:
        text = f.read()

    # å°†æ–‡ä»¶æŒ‰"å¼€å§‹ï¼Œ<epoch>:" åˆ†å‰²ï¼ˆç¤ºä¾‹è¡Œä¸­åŒ…å« "å¼€å§‹ï¼Œ1760046544.804822: ..."ï¼‰
    # ä¹Ÿå…¼å®¹æ¯è¡Œä¸€æ¡çš„æ ¼å¼ã€‚
    # æˆ‘ä»¬ä½¿ç”¨æ­£åˆ™åœ¨å…¨æ–‡æœ¬ä¸­æŸ¥æ‰¾æ¨¡å¼ï¼š å¼€å§‹ï¼Œ<epoch> : <attacker info line preceeding>
    # ä¸ºç¨³å¦¥ï¼Œå…ˆé€è¡Œå¤„ç†å¹¶ç”¨æ­£åˆ™æå–
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue

        # å°è¯•æå– epoch æ—¶é—´ï¼ˆfloatï¼‰
        m_time = re.search(r'å¼€å§‹[ï¼Œ,]\s*([0-9]+\.[0-9]+)\s*[:ï¼š]?', line)
        if m_time:
            start_epoch = float(m_time.group(1))
            # try to find attacker and target from previous or same line:
            # Look backwards a bit for a header that contains "æ”»å‡»è€…" or "-> ç›®æ ‡"
            # If the line itself contains "æ”»å‡»è€…", parse it
            # e.g. "*** æ”»å‡»è€… ['uav3'] -> ç›®æ ‡ uav2 (10.0.0.2) æ—¶é•¿=10s"
            # We'll attempt to extract attacker, target, ip, and duration from the line
            # First attempt full-line parse:
            header = line  # often the same line contains metadata
            # attempt to extract attacker list/bracket
            m_att = re.search(r"æ”»å‡»è€…\s*([^\s]+)", header)
            attacker = None
            if m_att:
                attacker = m_att.group(1)
            else:
                # fallback: look for "uavX" patterns
                m_att2 = re.search(r"\[?('?\"?uav[0-9]+'?\"?)\]?", header, re.IGNORECASE)
                if m_att2:
                    attacker = m_att2.group(1)

            # extract target name (after -> ç›®æ ‡)
            m_tgt = re.search(r"ç›®æ ‡\s*([^\s\(,ã€]+)", header)
            target = None
            if m_tgt:
                target = m_tgt.group(1)
            else:
                # fallback: look for "-> uavX"
                m_tgt2 = re.search(r"->\s*(uav[0-9]+)", header, re.IGNORECASE)
                if m_tgt2:
                    target = m_tgt2.group(1)

            # extract ip in parentheses if any
            m_ip = re.search(r"\(([\d\.]+)\)", header)
            ip = m_ip.group(1) if m_ip else None
            if ip and not target:
                target = ip

            # extract duration if present like æ—¶é•¿=10s or æ—¶é•¿=10
            m_dur = re.search(r"æ—¶é•¿\s*=\s*([0-9]+(?:\.[0-9]*)?)\s*s", header)
            if not m_dur:
                m_dur = re.search(r"æ—¶é•¿\s*=\s*([0-9]+(?:\.[0-9]*)?)", header)
            duration = float(m_dur.group(1)) if m_dur else default_duration

            attacks.append({
                'attack_id': id_counter,
                'attacker': attacker,
                'target': target if target else (ip if ip else ""),
                'attack_start_epoch': start_epoch,
                'duration': duration,
                'attack_end_epoch': start_epoch + duration
            })
            id_counter += 1
        else:
            # If no "å¼€å§‹" pattern in this line, try other common single-line pattern:
            # e.g. lines like: "*** æ”»å‡»è€… ['uav3'] -> ç›®æ ‡ uav2 (10.0.0.2) æ—¶é•¿=10s"
            m_header = re.search(r"\*\*\*.*æ”»å‡»è€…\s+([^\s]+).*->\s*ç›®æ ‡\s+([^\s\(]+).*æ—¶é•¿\s*=\s*([0-9]+(?:\.[0-9]*)?)s?", line)
            if m_header:
                attacker = m_header.group(1)
                target = m_header.group(2)
                duration = float(m_header.group(3))
                # no start time available here; skip unless a following "å¼€å§‹" line provides it
                # so continue
                continue
            # else skip line
            continue

    return attacks

def parse_conv_time_to_epoch(timestr, tzinfo=None):
    """
    å°† conversation History çš„ Time å­—ç¬¦ä¸²è½¬æ¢ä¸º epoch ç§’ã€‚
    æ”¯æŒå¤šç§å¸¸è§æ ¼å¼ï¼Œå¦‚:
      2025-9-26 11:47:39
      2025-09-26 11:47:39
    tzinfo: None æˆ– datetime.timezone å¯¹è±¡ æˆ–å­—ç¬¦ä¸² "+08:00" ç­‰ï¼ˆè‹¥ä¸ºå­—ç¬¦ä¸²ï¼Œåˆ™è§£æä¸ºå›ºå®šåç§»ï¼‰
    """
    s = timestr.strip()
    # try a list of formats
    fmts = [
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%d %H:%M",
        "%Y-%m-%d %H:%M:%S.%f",
        "%Y-%m-%d %H:%M:%S %z",
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%dT%H:%M:%S.%f",
        "%Y-%m-%d"
    ]
    dt = None
    for fmt in fmts:
        try:
            dt = datetime.strptime(s, fmt)
            break
        except Exception:
            pass

    if dt is None:
        # try to replace some unusual unicode punctuation and try again
        s2 = s.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '').replace('ï¼Œ', ' ').replace('ï¼š', ':')
        for fmt in fmts:
            try:
                dt = datetime.strptime(s2, fmt)
                break
            except Exception:
                pass

    if dt is None:
        # æœ€åå°è¯•æŒ‰ç…§ç©ºæ ¼åˆ†å‰²ï¼š"2025-9-26 11:47:39" -> pad month/day
        try:
            parts = s.split()
            if len(parts) >= 2:
                datep = parts[0].split('-')
                datep = [p.zfill(2) for p in datep]  # pad
                dates = "-".join(datep)
                s3 = dates + ' ' + parts[1]
                for fmt in fmts:
                    try:
                        dt = datetime.strptime(s3, fmt)
                        break
                    except Exception:
                        pass
        except Exception:
            dt = None

    if dt is None:
        raise ValueError(f"æ— æ³•è§£ææ—¶é—´å­—ç¬¦ä¸²: {timestr}")

    # apply timezone if provided
    if isinstance(tzinfo, str):
        # try parse "+08:00" or "UTC" etc; support only "+/-HH:MM" here
        if re.match(r'^[\+\-][0-9]{2}:[0-9]{2}$', tzinfo):
            sign = 1 if tzinfo[0] == '+' else -1
            hh = int(tzinfo[1:3])
            mm = int(tzinfo[4:6])
            offset = timedelta(hours=hh, minutes=mm) * sign
            tz = timezone(offset)
            dt = dt.replace(tzinfo=tz)
        else:
            # best-effort: if tzinfo == 'UTC' or 'utc'
            if tzinfo.upper() == 'UTC':
                dt = dt.replace(tzinfo=timezone.utc)
            else:
                # fallback: treat as naive (no tz)
                dt = dt
    elif isinstance(tzinfo, timezone):
        dt = dt.replace(tzinfo=tzinfo)
    else:
        # keep naive (assume UTC)
        dt = dt

    # if tzinfo not set, assume naive is UTC
    if dt.tzinfo is None:
        epoch = (dt - datetime(1970,1,1)).total_seconds()
    else:
        epoch = dt.timestamp()

    return epoch

def parse_conversation_history(path, timezone_hint=None):
    """
    è§£æ conversation_history.txtï¼Œè¿”å›æ£€æµ‹è®°å½•åˆ—è¡¨ï¼ˆassistant blocksï¼‰ï¼š
    æ¯æ¡è®°å½•ä¸º dict:
    {
      'conv_time_str': original time string,
      'conv_time_epoch': float,
      'assistant_json': dict  (è§£æåçš„ JSONï¼Œå¦‚æœå­˜åœ¨)
    }
    è§£æé€»è¾‘:
    - æ–‡ä»¶è¢«åˆ‡æˆå¤šä¸ªä¼šè¯å—ï¼Œå—å¤´å« "ğŸ“…ï¸ Time: 2025-9-26 11:47:39" (æˆ–ç±»ä¼¼)
    - åœ¨è¯¥å—ä¸­å¯»æ‰¾ assistant è¿”å›çš„ JSONï¼ˆå¤§æ‹¬å·å¼€å§‹çš„ JSONï¼‰ï¼Œå¹¶ json.loads
    - è‹¥è§£æå¤±è´¥ï¼Œä¼šå°½é‡åš text->json çš„ä¿®æ­£
    """
    with open(path, 'r', encoding='utf-8') as f:
        text = f.read()

    # å°†æ–‡ä»¶æŒ‰ "ğŸ“…ï¸ Time:" æˆ– "Time:" ç­‰åˆ†å‰²
    # æ‰¾åˆ°æ‰€æœ‰ "Time:" å‡ºç°ä½ç½®ï¼Œä¾æ¬¡æå–å—
    blocks = re.split(r"ğŸ“…ï¸\s*Time:|Time:", text)
    entries = []
    # blocks[0] æ˜¯åˆ†å‰²å‰çš„å‰å¯¼æ–‡æœ¬ï¼Œåç»­æ¯ä¸ªå—é¦–æœ‰æ—¶é—´è¡Œ
    for b in blocks[1:]:
        # b çš„å¼€å¤´åº”æ˜¯æ—¶é—´ï¼ˆç›´åˆ°æ¢è¡Œï¼‰
        first_line = b.strip().splitlines()[0].strip()
        time_str = first_line
        # å‰©ä½™ä¸ºå—ä½“
        body = "\n".join(b.strip().splitlines()[1:])

        # ä» body ä¸­æå– assistant è¿”å›çš„ JSONï¼ˆå‡è®¾ assistant åŒºå—ä»¥ "ğŸ‘‰ï¸[assistant]" æˆ–ç±»ä¼¼ï¼Œä¸”å†…å®¹æ˜¯ {...}ï¼‰
        # æ‰¾ç¬¬ä¸€ä¸ªå¤§æ‹¬å·å¯¹å¹¶å°è¯•è§£æ
        assistant_json = None
        # å°è¯•æŒ‰ "ğŸ‘‰ï¸[assistant]" æ ‡è®°åˆ†å—
        m_assist_block = re.search(r"ğŸ‘‰ï¸\[assistant\]\s*(\{.*\})", body, flags=re.DOTALL)
        json_text = None
        if m_assist_block:
            json_text = m_assist_block.group(1).strip()
        else:
            # å°è¯•å¯»æ‰¾ç¬¬ä¸€ä¸ªå¼€å¤§æ‹¬å·å¹¶åŒ¹é…åˆ°å¯¹åº”é—­æ‹¬å·ï¼ˆç®€å•ç­–ç•¥ï¼‰
            m_first = re.search(r"(\{[\s\S]*\})", body)
            if m_first:
                json_text = m_first.group(1)

        if json_text:
            # å¯èƒ½ json_text ä¸­å«æœ‰å°¾éšé€—å·æˆ–å¤šä½™çš„å°¾é€—å·ï¼Œéœ€è¦ä¿®æ­£
            try:
                assistant_json = json.loads(json_text)
            except Exception:
                # ä¿®æ­£å¸¸è§é—®é¢˜ï¼šå•å¼•å· -> åŒå¼•å·ï¼Œå°¾éšé€—å·ï¼ŒPython-style True/False -> true/false
                jt = json_text
                jt = jt.replace("'", '"')
                jt = re.sub(r",\s*}", "}", jt)
                jt = re.sub(r",\s*\]", "]", jt)
                jt = jt.replace('True', 'true').replace('False', 'false').replace('None', 'null')
                try:
                    assistant_json = json.loads(jt)
                except Exception:
                    # è§£æå¤±è´¥ï¼šä¿ç•™åŸå§‹æ–‡æœ¬ä½œä¸ºå­—ç¬¦ä¸²å­—æ®µ
                    assistant_json = {"_raw_assistant_text": json_text}

        # å°† time_str è½¬æ¢ä¸º epoch
        try:
            epoch = parse_conv_time_to_epoch(time_str, timezone_hint)
        except Exception as e:
            # è‹¥æ— æ³•è§£æï¼Œè®¾ç½®ä¸º None å¹¶ç»§ç»­
            epoch = None

        entries.append({
            'conv_time_str': time_str,
            'conv_time_epoch': epoch,
            'assistant_json': assistant_json,
            'body': body
        })

    return entries

def match_detections_to_attacks(attacks, conv_entries, default_duration=DEFAULT_ATTACK_DURATION):
    """
    å°†æ¯ä¸€æ¡ conv_entries ä¸­çš„æ£€æµ‹ç»“æœï¼ˆè‹¥å­˜åœ¨ï¼‰åŒ¹é…åˆ° attacks ä¸­ã€‚
    ç­–ç•¥ï¼š
      - è‹¥ conv entry çš„ conv_time_epoch åœ¨æŸä¸ª attack çš„ [start, end] åŒºé—´å†…ï¼Œåˆ™è§†ä¸ºå¯¹è¯¥æ”»å‡»çš„æ£€æµ‹/å“åº”
      - å¦‚æœå‘ç”Ÿå¤šæ¬¡ conv åŒ¹é…åŒä¸€ attackï¼Œåˆ™ä¿ç•™æœ€æ—©çš„æ£€æµ‹ï¼ˆdetection_time æœ€æ—©ï¼‰
    è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œé•¿åº¦ = len(attacks)ï¼Œæ¯ä¸ªå…ƒç´ ä¸º dict åŒ…å«æ”»å‡»åŸºæœ¬ä¿¡æ¯åŠæ£€æµ‹/é˜²å¾¡å­—æ®µ
    """
    # å¤åˆ¶ attacks ä»¥ä¾¿æ·»åŠ å­—æ®µ
    results = []
    # åˆå§‹åŒ–ç»“æœå­—å…¸
    for a in attacks:
        res = dict(a)  # åŒ…å« attack_id, attacker, target, attack_start_epoch, duration, attack_end_epoch
        res.update({
            'detection_time': None,
            'attack_detected': None,
            'attack_type': None,
            'security_score_cs': None,
            'defense_commands': None,
            'px4_command': None,
            'matched_conv_indices': []
        })
        results.append(res)

    # éå† conv_entriesï¼Œè‹¥ assistant_json ä¸­å«æœ‰ attack_detected ç­‰å­—æ®µï¼Œåˆ™å°è¯•åŒ¹é…
    for i, conv in enumerate(conv_entries):
        epoch = conv['conv_time_epoch']
        aj = conv['assistant_json'] or {}
        # check if assistant json contains attack info keys
        if not isinstance(aj, dict):
            continue
        # determine if this conv contains detection info: we expect keys like 'attack_detected' or 'attack_type' or 'security_score_cs'
        if not any(k in aj for k in ['attack_detected', 'attack_type', 'security_score_cs', 'defense_commands']):
            # ä¹Ÿå¯èƒ½ä½¿ç”¨ lower-case keys; try lower-cased keys
            lower_keys = {k.lower(): k for k in aj.keys()}
            mapped = {}
            if 'attack_detected' in lower_keys:
                mapped['attack_detected'] = aj[lower_keys['attack_detected']]
            # but simpler: skip if no meaningful keys
            if not any(k in aj for k in ['attack_detected', 'attack_type', 'security_score_cs', 'defense_commands']):
                continue

        # For entries that have epoch None, skip
        if epoch is None:
            continue

        # Attempt to match to each attack if epoch falls in [start, end]
        matched_any = False
        for res in results:
            start = res['attack_start_epoch']
            end = res.get('attack_end_epoch', start + default_duration)
            if start is None:
                continue
            # inclusive interval
            if start <= epoch <= end:
                matched_any = True
                # if detection_time not set or this conv is earlier, update
                if (res['detection_time'] is None) or (epoch < res['detection_time']):
                    res['detection_time'] = epoch
                    # copy fields from assistant json if present
                    # try to safely extract fields with default None
                    res['attack_detected'] = aj.get('attack_detected', res['attack_detected'])
                    res['attack_type'] = aj.get('attack_type', res['attack_type'])
                    res['security_score_cs'] = aj.get('security_score_cs', res['security_score_cs'])
                    # defense_commands may be list
                    dc = aj.get('defense_commands', aj.get('defense_command', aj.get('defense_cmds', None)))
                    res['defense_commands'] = dc
                    res['px4_command'] = aj.get('px4_command', res['px4_command'])
                # record which conv index matched
                res['matched_conv_indices'].append(i)
        # If not matched to any attack, we could try fuzzy matching (detection shortly after an attack start)
        if not matched_any:
            # optionally find nearest attack whose start time is within some slack window (e.g., 120s)
            slack = 120.0
            for res in results:
                start = res['attack_start_epoch']
                end = res.get('attack_end_epoch', start + default_duration)
                if start is None:
                    continue
                # if conv time is after start and within slack seconds after end, associate as well
                if start <= epoch <= end + slack:
                    if (res['detection_time'] is None) or (epoch < res['detection_time']):
                        res['detection_time'] = epoch
                        res['attack_detected'] = aj.get('attack_detected', res['attack_detected'])
                        res['attack_type'] = aj.get('attack_type', res['attack_type'])
                        res['security_score_cs'] = aj.get('security_score_cs', res['security_score_cs'])
                        res['defense_commands'] = aj.get('defense_commands', res['defense_commands'])
                        res['px4_command'] = aj.get('px4_command', res['px4_command'])
                    res['matched_conv_indices'].append(i)

    return results

def write_results_csv(results, out_path):
    """
    å°†ç»“æœå†™å…¥ CSVï¼ˆpandas DataFrameï¼‰ï¼Œå¯¹ defense_commands å’Œ matched_conv_indices åš JSON å­—ç¬¦ä¸²åŒ–
    """
    rows = []
    for r in results:
        row = {
            'attack_id': r.get('attack_id'),
            'attacker': json.dumps(r.get('attacker')),  # é˜²æ­¢åˆ—è¡¨/å­—ç¬¦ä¸²æ··ç”¨
            'target': r.get('target'),
            'attack_start': r.get('attack_start_epoch'),
            'attack_end': r.get('attack_end_epoch'),
            'detection_time': r.get('detection_time'),
            'attack_detected': r.get('attack_detected'),
            'attack_type': r.get('attack_type'),
            'security_score_cs': r.get('security_score_cs'),
            'defense_commands': json.dumps(r.get('defense_commands'), ensure_ascii=False) if r.get('defense_commands') is not None else None,
            'px4_command': r.get('px4_command'),
            'matched_conv_indices': json.dumps(r.get('matched_conv_indices', []))
        }
        rows.append(row)
    df = pd.DataFrame(rows)
    df.to_csv(out_path, index=False, encoding='utf-8-sig')
    print(f"Wrote {len(rows)} rows to {out_path}")

def main():
    parser = argparse.ArgumentParser(description="Extract attack+detection matching from attack.log and conversation_history.txt")
    parser.add_argument('--attack_log', default='attack.log')
    parser.add_argument('--conv_log', default='conversation_history.txt')
    parser.add_argument('--out', default='extracted_attacks.csv')
    parser.add_argument('--default_duration', type=float, default=DEFAULT_ATTACK_DURATION, help='é»˜è®¤æ”»å‡»æŒç»­æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œattack.log æœªæŒ‡å®šæ—¶ä½¿ç”¨')
    parser.add_argument('--timezone', default=None, help='å¯é€‰æ—¶åŒºæç¤ºï¼Œä¾‹å¦‚ "+08:00" æˆ– "UTC"ã€‚è‹¥æœªæŒ‡å®šï¼Œé»˜è®¤å°† conversation æ—¶é—´æŒ‰æœ¬åœ°/UTC è§£æã€‚')
    args = parser.parse_args()

    attacks = parse_attack_log(args.attack_log, default_duration=args.default_duration)
    print(f"Parsed {len(attacks)} attacks from {args.attack_log}")

    conv_entries = parse_conversation_history(args.conv_log, timezone_hint=args.timezone)
    print(f"Parsed {len(conv_entries)} conversation entries from {args.conv_log}")

    results = match_detections_to_attacks(attacks, conv_entries, default_duration=args.default_duration)
    write_results_csv(results, args.out)
    print("Done.")

if __name__ == '__main__':
    main()

